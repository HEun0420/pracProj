{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 영어 개 dog 고양이 cat 바나나 banana 커피 coffee 안경 glasses 바위 rock 시험 test 저장 save 긍정적인 positve 산독끼 Zinrabit 꼬라니 Zingorani\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "xslx_paths = 'test용사전엑셀.xlsx'\n",
    "xslx_loader = UnstructuredExcelLoader(xslx_paths, mode=\"elements\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = xslx_loader.load()\n",
    "\n",
    "# 문서 출력\n",
    "print(docs[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB Atlas 연결 설정\n",
    "# MONGODB_ATLAS_URI = \"\"\n",
    "# client = MongoClient(MONGODB_ATLAS_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "semantic_chunker = SemanticChunker(embeddings, breakpoint_threshold_type=\"percentile\")\n",
    "semantic_chunks = semantic_chunker.create_documents([d.page_content for d in docs])\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=semantic_chunks, \n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# mongoDB 활용시\n",
    "# vectorstore = MongoDBAtlasVectorSearch(\n",
    "#     collection_name=\"semantic_chunks\",\n",
    "#     embedding=embeddings,\n",
    "#     client=client\n",
    "# )\n",
    "\n",
    "vectorstore.add_documents(semantic_chunks)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201\\AppData\\Local\\Temp\\ipykernel_12816\\144438238.py:9: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "C:\\Users\\201\\AppData\\Local\\Temp\\ipykernel_12816\\144438238.py:17: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  trans_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
      "C:\\Users\\201\\AppData\\Local\\Temp\\ipykernel_12816\\144438238.py:24: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  translation_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# Embedding 설정 및 chunking\n",
    "embeddings = OpenAIEmbeddings()\n",
    "semantic_chunker = SemanticChunker(embeddings, breakpoint_threshold_type=\"percentile\")\n",
    "semantic_chunks = semantic_chunker.create_documents([d.page_content for d in docs])\n",
    "\n",
    "# FAISS vectorstore 생성\n",
    "vectorstore = FAISS.from_documents(documents=semantic_chunks, embedding=embeddings)\n",
    "\n",
    "# 번역을 위한 PromptTemplate 및 Chain 설정\n",
    "trans_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"다음 텍스트를 영어로 번역해주세요: {text}\"\n",
    ")\n",
    "\n",
    "translation_chain = LLMChain(\n",
    "    llm=trans_llm,\n",
    "    prompt=translation_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201\\AppData\\Local\\Temp\\ipykernel_12816\\2160264360.py:17: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  translation_result = translation_chain.run(text=combined_relevant_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 쿼리: 산독끼는 꼬라니를 좋아해. 바나나도 좋아해\n",
      "검색된 관련 텍스트: 한국어 영어 개 dog 고양이 cat 바나나 banana 커피 coffee 안경 glasses 바위 rock 시험 test 저장 save 긍정적인 positve 산독끼 Zinrabit 꼬라니 Zingorani 한국어 영어 개 dog 고양이 cat 바나나 banana 커피 coffee 안경 glasses 바위 rock 시험 test 저장 save 긍정적인 positve 산독끼 Zinrabit 꼬라니 Zingorani 한국어 영어 개 dog 고양이 cat 바나나 banana 커피 coffee 안경 glasses 바위 rock 시험 test 저장 save 긍정적인 positve 산독끼 Zinrabit 꼬라니 Zingorani 한국어 영어 개 dog 고양이 cat 바나나 banana 커피 coffee 안경 glasses 바위 rock 시험 test 저장 save 긍정적인 positve 산독끼 Zinrabit 꼬라니 Zingorani 한국어 영어 개 dog 고양이 cat 바나나 banana 커피 coffee 안경 glasses 바위 rock 시험 test 저장 save 긍정적인 positve 산독끼 Zinrabit 꼬라니 Zingorani\n",
      "번역 결과: Here is the translated text in English:\n",
      "\n",
      "Korean English\n",
      "Dog dog\n",
      "Cat cat\n",
      "Banana banana\n",
      "Coffee coffee\n",
      "Glasses glasses\n",
      "Rock rock\n",
      "Test test\n",
      "Save save\n",
      "Positive positive\n",
      "산독끼 Zinrabit\n",
      "꼬라니 Zingorani\n",
      "\n",
      "Korean English\n",
      "Dog dog\n",
      "Cat cat\n",
      "Banana banana\n",
      "Coffee coffee\n",
      "Glasses glasses\n",
      "Rock rock\n",
      "Test test\n",
      "Save save\n",
      "Positive positive\n",
      "산독끼 Zinrabit\n",
      "꼬라니 Zingorani\n",
      "\n",
      "Korean English\n",
      "Dog dog\n",
      "Cat cat\n",
      "Banana banana\n",
      "Coffee coffee\n",
      "Glasses glasses\n",
      "Rock rock\n",
      "Test test\n",
      "Save save\n",
      "Positive positive\n",
      "산독끼 Zinrabit\n",
      "꼬라니 Zingorani\n",
      "\n",
      "Korean English\n",
      "Dog dog\n",
      "Cat cat\n",
      "Banana banana\n",
      "Coffee coffee\n",
      "Glasses glasses\n",
      "Rock rock\n",
      "Test test\n",
      "Save save\n",
      "Positive positive\n",
      "산독끼 Zinrabit\n",
      "꼬라니 Zingorani\n",
      "\n",
      "Korean English\n",
      "Dog dog\n",
      "Cat cat\n",
      "Banana banana\n",
      "Coffee coffee\n",
      "Glasses glasses\n",
      "Rock rock\n",
      "Test test\n",
      "Save save\n",
      "Positive positive\n",
      "산독끼 Zinrabit\n",
      "꼬라니 Zingorani\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 쿼리\n",
    "query = \"산독끼는 꼬라니를 좋아해. 바나나도 좋아해\"\n",
    "\n",
    "# Step 1: 쿼리에서 단어를 추출하고 vectorstore에서 관련 문서 검색\n",
    "query_words = query.split(\" \")  # 쿼리에서 단어들을 추출\n",
    "relevant_texts = []\n",
    "\n",
    "# query 단어에 대해 vectorstore에서 관련 문서 찾기\n",
    "for word in query_words:\n",
    "    search_results = vectorstore.similarity_search(word, k=5)  # 해당 단어와 관련된 문서 검색\n",
    "    for result in search_results:\n",
    "        # 검색된 결과에서 실제 텍스트를 relevant_texts에 추가\n",
    "        relevant_texts.append(result.page_content)\n",
    "\n",
    "# Step 2: 검색된 문서들을 하나로 결합 (검색된 관련 문서만 결합)\n",
    "# query에 포함된 단어들만 포함된 부분을 추출하여 연결\n",
    "filtered_relevant_texts = []\n",
    "for text in relevant_texts:\n",
    "    if any(word in text for word in query_words):\n",
    "        filtered_relevant_texts.append(text)\n",
    "\n",
    "# 관련된 문서들을 하나로 결합\n",
    "combined_relevant_text = \" \".join(filtered_relevant_texts)  # 관련 문서들을 하나로 결합\n",
    "\n",
    "# Step 3: 관련 문서들을 번역\n",
    "translation_result = translation_chain.run(text=combined_relevant_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"원본 쿼리:\", query)\n",
    "print(\"검색된 관련 텍스트:\", combined_relevant_text)\n",
    "print(\"번역 결과:\", translation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201\\AppData\\Local\\Temp\\ipykernel_2728\\4020573920.py:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  translation_result = translation_chain.run(words=words_to_translate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 단어들: 산독끼, 꼬라니, 바나나, 개, 고양이, 커피, 안경, 바위, 시험\n",
      "번역 결과: 다음 단어들의 영어 번역은 다음과 같습니다:\n",
      "\n",
      "- 산독끼: mountain goat (산악 염소)\n",
      "- 꼬라니: (이 단어는 특정한 의미가 없거나 잘 알려지지 않은 단어입니다. 추가적인 맥락이 필요합니다.)\n",
      "- 바나나: banana\n",
      "- 개: dog\n",
      "- 고양이: cat\n",
      "- 커피: coffee\n",
      "- 안경: glasses\n",
      "- 바위: rock\n",
      "- 시험: exam (또는 test)\n",
      "\n",
      "꼬라니에 대한 추가 정보가 필요하면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# OpenAI 모델 설정\n",
    "trans_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 번역을 위한 PromptTemplate 설정\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"words\"],\n",
    "    template=\"다음 단어들을 영어로 번역해주세요: {words}\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "translation_chain = LLMChain(\n",
    "    llm=trans_llm,\n",
    "    prompt=translation_prompt\n",
    ")\n",
    "\n",
    "# 번역 요청할 단어들\n",
    "words_to_translate = \"산독끼, 꼬라니, 바나나, 개, 고양이, 커피, 안경, 바위, 시험\"\n",
    "\n",
    "# 번역 실행\n",
    "translation_result = translation_chain.run(words=words_to_translate)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"원본 단어들:\", words_to_translate)\n",
    "print(\"번역 결과:\", translation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
