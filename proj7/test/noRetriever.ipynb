{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from pymongo import MongoClient\n",
    "from langchain_community.vectorstores import MongoDBAtlasVectorSearch\n",
    "import os\n",
    "\n",
    "# 1. 엑셀 파일 로드 및 문서로 변환\n",
    "xlsx_path = 'test용사전엑셀.xlsx'\n",
    "xlsx_loader = UnstructuredExcelLoader(xlsx_path, mode=\"elements\")\n",
    "docs = xlsx_loader.load()  # 로드된 원본 문서\n",
    "\n",
    "# 2. Embeddings 및 문서 분할 설정\n",
    "embeddings = OpenAIEmbeddings()\n",
    "semantic_chunker = SemanticChunker(embeddings, breakpoint_threshold_type=\"percentile\")\n",
    "semantic_chunks = semantic_chunker.create_documents([d.page_content for d in docs])\n",
    "\n",
    "# 3. MongoDB 연결 설정\n",
    "MONGODB_ATLAS_CLUSTER_URI = os.getenv(\"MONGODB_ATLAS_CLUSTER_URI\")\n",
    "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n",
    "\n",
    "db_name = \"test\"\n",
    "collection_name = \"col\"\n",
    "\n",
    "# MongoDB 컬렉션 객체 가져오기\n",
    "collection = client[db_name][collection_name]\n",
    "\n",
    "# 4. Vector Search 초기화 (chunked 문서 사용)\n",
    "vector_search = MongoDBAtlasVectorSearch.from_documents(\n",
    "    documents=semantic_chunks,  # **chunker로 분할된 문서 사용**\n",
    "    embedding=embeddings,      # Embedding 모델\n",
    "    collection=collection      # MongoDB 컬렉션\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역 결과: The translation of the sentence \"산독끼는 바나나와 꼬라니를 좋아해.\" is \"Sandoqki likes bananas and corani.\"\n"
     ]
    }
   ],
   "source": [
    "# 번역을 위한 PromptTemplate 설정\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"retrieved_text\", \"query\"],\n",
    "    template=\"\"\" \n",
    "다음은 한국어 텍스트와 관련된 참고 자료입니다:\n",
    "참고 자료: {retrieved_text}\n",
    "\n",
    "위 자료를 기반으로, 아래 한국어 문장을 영어로 번역해주세요.\n",
    "문장: {query}\n",
    "번역:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# LLM 모델 설정 (OpenAI GPT-4)\n",
    "trans_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 번역 체인 설정\n",
    "translation_chain = LLMChain(\n",
    "    llm=trans_llm, \n",
    "    prompt=translation_prompt\n",
    ")\n",
    "\n",
    "# MongoDB에서 관련 데이터를 검색\n",
    "query = \"산독끼는 바나나와 꼬라니를 좋아해.\"\n",
    "\n",
    "# MongoDB에서 검색하여 관련 텍스트 추출\n",
    "words = query.split()  # 쿼리에서 단어들로 분할\n",
    "\n",
    "# DB에서 해당 단어에 대한 번역 데이터를 찾는 부분\n",
    "retrieved_text = \"\"\n",
    "for word in words:\n",
    "    result = collection.find_one({\"text\": {\"$regex\": word}})\n",
    "    if result:\n",
    "        english_translation = result.get('text', '').split()  # 해당 단어의 번역 결과\n",
    "        retrieved_text += \" \".join(english_translation) + \" \"\n",
    "\n",
    "# LLM으로 번역 결과 얻기\n",
    "result = translation_chain.run({\"retrieved_text\": retrieved_text.strip(), \"query\": query})\n",
    "\n",
    "# 번역 결과 출력\n",
    "print(\"번역 결과:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
